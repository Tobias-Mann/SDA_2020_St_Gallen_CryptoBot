# Single-Timeseries-Crypto-Bot
In this collaborative project we build a trading bot, which analysis a single timeseries of crypto currency prices to identify optimal conditions for entry and exit trades in real-time.

# The Simulation Framework
In orderto realistically simulate a bot wich takes in price data and makes a trading decision in realtime, an extensive collection of python classes has been utilized that modularize the simulation in multile elements. The logic is best decribed by an actual trader observing market prices and making a decision to by or sell. In this case the so called "decisionmaker" decides on the order to be opened, for instance "buy 100 BTC @7563.48". Such decisions are tracked in another class called "Orderbook" (the name is admittedly somewaht confusing, but does not model a full orderbook as other market participants entering orders are not part of the simulation). The "Simulator" class is responsible for taking in new price data, checking if any Orders from the Orderbook can be executed given Open High Low and Closing price of the next period and feeds in the closing price into a memory which can be accessed by the aforementioned decisionmaker. (The decisonmaker currently onyl consideres closing prices)
If the Simulator finds an order from the Orderbook can be exectuted the Order is moved to a "Transactionbook", this action causes an update of the simulated "Portfolio" which keeps track of the BTC position and USD Cash position at each transaction. Furhtermore, the portfolio class facilitates performance data due to functions such as portfolio_repricing, or tearsheet, which allow to find the peortfolio value and performance for any point in time for that price data is provided to these functions. Additionaly, the property portfolio_over_time provides easy access to the portfolio positions and prices at each time of a transaction (admittedly there is some redundancy with the transactionbook).
Lastly the logic that ultimately determines the trades is defined by extensions to the decisionmaker model those again are devided into "simple strategies" and "smart strategies". Simple strategies are following a deterministic rule. For instance, calculate RSI for current period and go all in with a market order if the calculated RSI is below 30 and there is no open position, or if there is already an open position and the RSI is above 70, sell everything by market order.
The "smart strategies" are based on a flexible q-learning agent model and are furhter described in the next section. The below Graphic aims to visualize the described Framework.


<p align="center"><img src="https://github.com/Tobias-Mann/Single-Timeseries-Crypto-Bot/blob/main/Images/Smart%20Data.png?raw=true" /></p>

# The Framework for QLearning Strategies
Using the simulationframework described above, this repository contains additional classes and examples to extend the functionality of the decisionmaker class with a QLearnign Model. To facilitate such an extension an "agent" is assigend to the decisionmaker, this agent utilizes its own framework to suggest the best action. The provided example (smartbalancer) uses an action space of 3 actions to optimize the share of BTC in the portfolio. The possible actions are the following:

- 0% : Execute orders so there is no BTC exposure/ Portfolio is a simple cash position
- 50%: Execute orders so there is a 50% BTC exposure/ the portfolio results in an approximately equal wighting of cash and BTC
- 100%: Execute orders so the portfolio has the largest possible BTC exposure/ buy as much BTC as possible with funds in portfolio

The Agent accessess all previously observed prices and chooses an action based on the price history. The action is the executed in the decisionmaker by filling the orderbook, as in the logik above. In order to use QLearnig for this process of choosing the right action, the evergrowing number of observed prices needs to be converted into a finite number of features. To enabel this, feature objects are defined which hold information on:
- a minimum of observations required to calculate the feature, 
- logical restictions of maximum and minimum values (neccessary to define the q-table)
- the logic to caluclate the feature value at any given point in time given a sufficent number of past observations

The Q agent class has an environment which is the collection of its possible actions and an observationspace. The observationspace is a class which represents in turn a collection of features. Due to this construction model it is possible to dynamically define an observationspace and an actionspace, which is used by the agent to initialize its q-table.
After knowing its observationspace and actionspace, the agent can be assigend to a decisionmaker (e.g. smartbalancer). The decisionmaker then waits until enough prices have been observed to calculate all features that the agent requires and when the agent is ready to act it enteres new orders according to the portfolio weightings suggested by the agent.

Note, the agent class is desigend in a way to support random exploration of its q-table. The default is an epsiolon (porbability of random action) of 50% which decayes each period for the first 10000 periods. Parameters typically associated with QLearning can be assigend to the agent class. in particular epsilon, a discout rate for the reward function and a learning rate value for the updating of table values.


# Testing a QLearning Strategy by Monthe Carlo Simulation

For multiplereasons, a single simulation of a Q-Learning model is not yielding a realistic idea of the expected return generated by this strategy. Some notable arguments for the neccessity of running multiple simulations are the following.

- The decision rule of the Agent (Q-Tabel) is initialized by random values, a strategy/q-table that might perform well in sample can still have no predictive power. When such a table is tested outsied the sample data it might reveal that any in sample returns were purely based on a spureous correllation.
- The simulator class utilizes random numbers to simulate market prices. However, a single simulation might result in a performance that is rather driven by lucky random prices than by a feasable trading strategy. Outperformance is less likely over longer simulation periods, but there is always a small probability that a single simulation performs well because of such random prices and not because of the quality of the strategy itself.
- A single simulation might get stuck with suboptimal bahavior and thus not find an optimal solution.(Eventhough this is unlikely due to the Q-Learning algo including random exploration)

For each of the above reasons it is desirable to run multiple simulations and consider their distribution rather than a single realization of these strategies. This would also be optimal for the afore discussed "Simple Strategies". However, these follow a purely deterministic decision rule, while the q learning is even more vulnerable to random effects, due to the random initialization of the model.
The below plot shows a Q-Learning algorithm (features: 1 period return, 60 periods return, 20 periods deviation from mean, 60 period deviation from mean, 14 periods RSI, Actions: 0% BTC, 50% BTC, 100% BTC in the Portfolio) using simulated market orders. The black line indicates the average performance for Dec 2019 over 100 simulations with different random seeds. While the blue areas mark the 100%, 90%, 60% probability mass of returns generated by such a strategy. Notably, the red line displays the performance of a 100% exposure to BTC for the same period. While at first sight the strategy appears to outperfrom a simple long exposure to Bitcoin it mus be noted that the simulation did not account for any transaction costs like comissions, or spreads and fruthermore, it does not take into account liquidity constraints. Therefore, while the strategy might be capable of identifying those moment in wich holding BTC is relatively desirable, it cannot be expected that deploying such an algorithm does result in outperforming BTC and might not even generate positive returns at all.
<p align="center"><img src="https://github.com/Tobias-Mann/Single-Timeseries-Crypto-Bot/blob/main/Images/MonteCarloDistribution.png?raw=true" /></p>
<p align="center"><img src="https://github.com/Tobias-Mann/Single-Timeseries-Crypto-Bot/blob/main/Images/Nov17.png?raw=true" /></p>
